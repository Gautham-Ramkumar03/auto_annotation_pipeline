Hey chat i want to you to make me an amazing prompt :
The prompt should be best suited for models gpt 4o, claude 3.5 sonnet , deepseek 3
The prompt must utilize the maximum value and able to use these tools the most efficient way possible following all of the rules of prompt engineering based on the context of my message

Context of my message :

I want to make a python script that takes a folder as input , takes all of the video files in the folder (any video format like mp4 , avi etc ) and automatically converts them into a data set , the output will be a folder of train , test , val folders inside a folder called dataset , the split should be entered as custom , it must ask whether we want the full folder as train or a custom split we have in mind or reccomended split (70/20/10) , i also want the option of image augmentation , it can be turned on or off , if we turn on image augmentation , it must use the best reccomended image augmentation techniques , so that the dataset will be more robust and the model trained from the dataset will be more accurate , i am collecting data for cracks on roads , walls , tunnels , lane fadings , pole rust , crack on poles etc , so the image augmentation must be useful for that purpose , make sure that the output will be a perfect dataset made from video , the data set must take very varied images from video , dont take every frame as an image , i want the dataset to be varied , imagine the video was collected on a moving vehicle of 25 kmph, i also want the output image choice , png or jpg or something else

Develop a comprehensive Python script that ingests a folder of video files (supporting any common format such as mp4, avi, etc.) and automatically converts them into a well-structured and robust dataset for machine learning. The dataset must be tailored for training models to detect defects like cracks on roads, walls, tunnels, lane fadings, pole rust, and cracks on poles.

Requirements & Specifications:

    Input Handling:
        The script must prompt the user to enter a folder path containing video files.
        It should iterate through the folder and process all videos regardless of format.

    Intelligent Frame Extraction:
        Extract frames in a way that ensures high variability and diversity—avoid extracting every frame.
        Implement a strategy to sample frames that captures varied images (e.g., based on a fixed time interval, scene change detection, or motion analysis, considering a video recorded at around 25 km/h).
        Ensure the selected frames represent distinct visual conditions to build a robust dataset.

    Dataset Structure & Splitting:
        Create a main output directory named dataset with subdirectories: train, test, and val.
        Prompt the user for the dataset splitting method:
            Option A: Use the entire set of extracted frames as training data.
            Option B: Allow the user to input a custom split percentage.
            Option C: Provide a recommended default split (70% train, 20% test, 10% validation).
        Organize the extracted frames accordingly into the respective subfolders.

    Image Augmentation (Optional):
        Ask the user whether to enable image augmentation.
        If enabled, apply state-of-the-art augmentation techniques aimed at enhancing detection robustness for cracks and similar defects. These should include:
            Rotations, flips, and perspective transformations.
            Adjustments to brightness, contrast, and saturation.
            Noise addition, zoom, and slight blurring.
        The augmentation pipeline should be modular so that it can be easily turned on/off and fine-tuned for the target application.
        
     Output Format:
        Allow the user to choose the output image format (e.g., PNG, JPEG, or another format).

    Code Quality and Efficiency:
        Write modular, well-documented, and self-contained code with clear inline comments.
        Use established libraries such as OpenCV for video processing and libraries like Albumentations, torchvision, or similar for image augmentation.
        Include robust error handling to deal with various file formats and unexpected input issues.
        Optimize frame extraction and processing to handle potentially large video files efficiently.

    Additional Considerations:
        Ensure that the dataset is varied enough to avoid redundancy and covers different lighting, angles, and environmental conditions typical for outdoor scenarios.
        The code should be ready to integrate with further training pipelines, making the dataset “perfect” for robust model training.
        Include clear prompts for all user inputs (folder path, dataset split options, augmentation toggle).

Deliverable:
Generate and output a complete Python script fulfilling the above requirements. The script should be ready to run with minimal additional configuration, and all steps (from video processing to dataset creation) should be clearly commented and modular.

Create a complete, production-ready Python script that processes a folder of video files and automatically converts them into a robust dataset for machine learning applications, specifically for detecting defects such as cracks on roads, walls, tunnels, lane fadings, pole rust, and cracks on poles.

Requirements:

    Input Handling:
        Accept a folder path as input and automatically detect all video files within it (support common formats such as MP4, AVI, etc.).
    Frame Extraction:
        Process each video by sampling frames intelligently to ensure a varied dataset. Do not extract every frame; instead, select frames based on the context of a moving vehicle (assume a speed of 25 km/h) to capture diverse and representative images.
    Dataset Split Options:
        Prompt the user to choose the dataset split strategy:
            Use the full folder as the training set, or
            Define a custom split, or
            Use a recommended split (70% training, 20% testing, 10% validation).
        Organize the output into a directory structure with a main folder named dataset that contains subfolders train, test, and val.
    Image Augmentation (Optional):
        Provide an option to enable or disable image augmentation.
        If augmentation is enabled, apply state-of-the-art augmentation techniques (such as rotation, scaling, brightness/contrast adjustments, perspective transforms, etc.) that are specifically effective for enhancing images of cracks and related defects.
        Use robust image augmentation libraries (e.g., Albumentations or imgaug) and ensure the augmented data will improve model robustness and accuracy.
    Output Format:
        Allow the user to choose the output image format (e.g., PNG, JPEG, or another format).
    Coding Standards:
        Write modular, well-commented, and error-handled code.
        Utilize standard Python libraries such as OpenCV for video processing, os/argparse for file management and command-line interaction, and relevant libraries for image augmentation.
        Ensure the script is maintainable and extensible, with clear inline documentation for each major section of the workflow.

Deliverable:
Provide the complete Python script along with explanations for each section where appropriate. The code should be production-ready and demonstrate expert knowledge in Python programming, video processing, and dataset creation for machine learning.
